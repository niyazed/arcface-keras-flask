{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import argparse\n",
    "from glob import glob\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, LearningRateScheduler, TerminateOnNaN, LambdaCallback\n",
    "from keras import Model, optimizers\n",
    "from keras import regularizers\n",
    "\n",
    "import archs\n",
    "from metrics import *\n",
    "from scheduler import *\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "# le = preprocessing.LabelEncoder()\n",
    "\n",
    "# def load_data():\n",
    "#     X = np.load('data/color_image.npy',allow_pickle=True)\n",
    "#     y = np.load('data/label.npy',allow_pickle=True)\n",
    "    \n",
    "#     # le.fit(y)\n",
    "#     # print(le.classes_)\n",
    "#     # y = le.transform(y)\n",
    "#     # print(X.shape, y.shape)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "#     np.savez_compressed('celebrity-faces-dataset.npz', X_train, X_test, y_train, y_test)\n",
    "    \n",
    "# load_data()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the face dataset\n",
    "data = np.load('celebrity-faces-dataset.npz')\n",
    "trainX, testX, trainy, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Sample: \", trainX.shape, \" || \", \"Training Labels: \", trainy.shape)\n",
    "print(\"Testing Sample: \", testX.shape, \" || \", \"Testing Labels: \", testy.shape)\n",
    "\n",
    "# trainX = trainX[:, :, :, np.newaxis].astype('float32') / 255\n",
    "# testX = testX[:, :, :, np.newaxis].astype('float32') / 255\n",
    "\n",
    "#for RGB Image\n",
    "trainX = trainX.astype('float32') / 255\n",
    "testX = testX.astype('float32') / 255\n",
    "\n",
    "# print(\"----------NORMALIZED & RESHAPED----------\")\n",
    "# print(\"Training Sample: \", trainX.shape, \" || \", \"Training Labels: \", trainy.shape)\n",
    "# print(\"Testing Sample: \", testX.shape, \" || \", \"Testing Labels: \", testy.shape)\n",
    "\n",
    "# trainy = keras.utils.to_categorical(trainy, 10)\n",
    "# testy = keras.utils.to_categorical(testy, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the data\n",
    "# trainX = np.reshape(trainX,(trainX.shape[0],trainX.shape[1],trainX.shape[2],1))\n",
    "# testX = np.reshape(testX,(testX.shape[0],testX.shape[1],testX.shape[2],1))\n",
    "# print(trainX.shape, testX.shape)\n",
    "print(testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10000\n",
    "IMG_W = 128\n",
    "IMG_H = 128\n",
    "IMG_CHNL = 3\n",
    "LR = 1e-2\n",
    "NUM_CLASSES = 10\n",
    "WEIGHT_DECAY = 1e-3\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    input = Input(shape=(IMG_W, IMG_H, IMG_CHNL))\n",
    "    label = Input(shape=(NUM_CLASSES,))\n",
    "\n",
    "    x = Conv2D(16, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(WEIGHT_DECAY))(input)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(32, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(WEIGHT_DECAY))(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(WEIGHT_DECAY))(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(WEIGHT_DECAY))(x) # kernel_regularizer=regularizers.l2(WEIGHT_DECAY)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    output = ArcFace(NUM_CLASSES, regularizer=regularizers.l2(WEIGHT_DECAY))([x, label]) # regularizer=regularizers.l2(WEIGHT_DECAY)\n",
    "\n",
    "    model = Model([input, label], output)\n",
    "\n",
    "    model.load_weights('models/model.hdf5')\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=SGD(lr=LR, momentum=0.5),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(samples):\n",
    "    af_model = build_model()\n",
    "    af_model = Model(inputs=af_model.input[0], outputs=af_model.layers[-3].output)\n",
    "    emd_features = af_model.predict(samples, verbose=1)\n",
    "    emd_features /= np.linalg.norm(emd_features, axis=1, keepdims=True)\n",
    "    \n",
    "    return emd_features\n",
    "\n",
    "# For training set\n",
    "emdtrainX = get_embedding(trainX)\n",
    "emdTrainX = np.asarray(emdtrainX)\n",
    "print(emdTrainX.shape)\n",
    "\n",
    "# For testing set\n",
    "emdtestX = get_embedding(testX)\n",
    "emdtestX = np.asarray(emdtestX)\n",
    "print(emdtestX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('celebrity-faces-embeddings.npz', emdTrainX, trainy, emdTestX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "print(\"Dataset: train=%d, test=%d\" % (emdTrainX.shape[0], emdTestX.shape[0]))\n",
    "\n",
    "# normalize input vectors\n",
    "in_encoder = Normalizer()\n",
    "emdTrainX_norm = in_encoder.transform(emdTrainX)\n",
    "emdTestX_norm = in_encoder.transform(emdTestX)\n",
    "\n",
    "# label encode targets\n",
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(trainy)\n",
    "trainy_enc = out_encoder.transform(trainy)\n",
    "testy_enc = out_encoder.transform(testy)\n",
    "\n",
    "print(out_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model = SVC(kernel='linear', probability=True)\n",
    "model.fit(emdTrainX_norm, trainy_enc)\n",
    "# predict\n",
    "yhat_train = model.predict(emdTrainX_norm)\n",
    "yhat_test = model.predict(emdTestX_norm)\n",
    "# score\n",
    "score_train = accuracy_score(trainy_enc, yhat_train)\n",
    "score_test = accuracy_score(testy_enc, yhat_test)\n",
    "# summarize\n",
    "print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "# select a random face from test set\n",
    "selection = choice([i for i in range(testX.shape[0])])\n",
    "random_face = testX[selection]\n",
    "random_face_emd = emdTestX_norm[selection]\n",
    "random_face_class = testy_enc[selection]\n",
    "random_face_name = out_encoder.inverse_transform([random_face_class])\n",
    "\n",
    "# prediction for the face\n",
    "samples = np.expand_dims(random_face_emd, axis=0)\n",
    "yhat_class = model.predict(samples)\n",
    "yhat_prob = model.predict_proba(samples)\n",
    "# get name\n",
    "class_index = yhat_class[0]\n",
    "class_probability = yhat_prob[0,class_index] * 100\n",
    "predict_names = out_encoder.inverse_transform(yhat_class)\n",
    "all_names = out_encoder.inverse_transform([0,1,2,3,4,5,6,7,8,9])\n",
    "print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\n",
    "# print('Predicted: \\n%s \\n%s' % (all_names, yhat_prob[0]*100))\n",
    "# print('Expected: %s' % random_face_name[0])\n",
    "# plot face\n",
    "plt.imshow(random_face)\n",
    "title = '%s (%.3f)' % (predict_names[0], class_probability)\n",
    "plt.title(title)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# SVM_MODEL LOAD FOR PREDICTION\n",
    "model = joblib.load('models/svm_model.sav')\n",
    "in_encoder = Normalizer()\n",
    "out_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "labels = np.load('data/label.npy',allow_pickle=True)\n",
    "out_encoder.fit(labels)\n",
    "\n",
    "face_img = cv2.imread('daddario.jpg',1)\n",
    "# face_img = face_img.astype('float32') / 255\n",
    "rgb_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(rgb_img, (128,128))\n",
    "\n",
    "\n",
    "img = np.reshape(img, (1,img.shape[0], img.shape[1], img.shape[2]))\n",
    "img_emd = np.asarray(get_embedding(img)) # converting embedded image to numpy array if needed\n",
    "\n",
    "\n",
    "\n",
    "img_norm = in_encoder.transform(img_emd)\n",
    "yhat_class = model.predict(img_norm)\n",
    "yhat_prob = model.predict_proba(img_norm)\n",
    "\n",
    "\n",
    "class_index = yhat_class[0]\n",
    "class_probability = yhat_prob[0,class_index] * 100\n",
    "predict_names = out_encoder.inverse_transform(yhat_class)\n",
    "\n",
    "\n",
    "plt.imshow(rgb_img)\n",
    "title = '%s (%.3f)' % (predict_names[0], class_probability)\n",
    "plt.title(title)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = np.load('data/label.npy',allow_pickle=True)\n",
    "\n",
    "le.fit(y)\n",
    "# print(le.classes_)\n",
    "y = le.inverse_transform([0,1,2,3,4,5,6,7,8,9])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.externals import joblib\n",
    "\n",
    "# filename = 'models/svm_model.sav'\n",
    "# joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
